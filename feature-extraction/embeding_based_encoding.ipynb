{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeding 기반 encoder\n",
    "data\n",
    "*   data/vector_*{vector_size}*_embeding_X.csv\n",
    "*   data/vector_*{vector_size}*_embeding_X_test.csv\n",
    "\n",
    "model \n",
    "*   label_encoding_mutation_model_vector_*{vector_size}*.w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/train.csv\")\n",
    "test = pd.read_csv(\"../data/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원래 레이블: ACC, 변환된 숫자: 0\n",
      "원래 레이블: BLCA, 변환된 숫자: 1\n",
      "원래 레이블: BRCA, 변환된 숫자: 2\n",
      "원래 레이블: CESC, 변환된 숫자: 3\n",
      "원래 레이블: COAD, 변환된 숫자: 4\n",
      "원래 레이블: DLBC, 변환된 숫자: 5\n",
      "원래 레이블: GBMLGG, 변환된 숫자: 6\n",
      "원래 레이블: HNSC, 변환된 숫자: 7\n",
      "원래 레이블: KIPAN, 변환된 숫자: 8\n",
      "원래 레이블: KIRC, 변환된 숫자: 9\n",
      "원래 레이블: LAML, 변환된 숫자: 10\n",
      "원래 레이블: LGG, 변환된 숫자: 11\n",
      "원래 레이블: LIHC, 변환된 숫자: 12\n",
      "원래 레이블: LUAD, 변환된 숫자: 13\n",
      "원래 레이블: LUSC, 변환된 숫자: 14\n",
      "원래 레이블: OV, 변환된 숫자: 15\n",
      "원래 레이블: PAAD, 변환된 숫자: 16\n",
      "원래 레이블: PCPG, 변환된 숫자: 17\n",
      "원래 레이블: PRAD, 변환된 숫자: 18\n",
      "원래 레이블: SARC, 변환된 숫자: 19\n",
      "원래 레이블: SKCM, 변환된 숫자: 20\n",
      "원래 레이블: STES, 변환된 숫자: 21\n",
      "원래 레이블: TGCT, 변환된 숫자: 22\n",
      "원래 레이블: THCA, 변환된 숫자: 23\n",
      "원래 레이블: THYM, 변환된 숫자: 24\n",
      "원래 레이블: UCEC, 변환된 숫자: 25\n"
     ]
    }
   ],
   "source": [
    "# SUBCLASS 가 범주형이기 때문에 LabelEncoder 사용\n",
    "le_subclass = LabelEncoder()\n",
    "train['SUBCLASS'] = le_subclass.fit_transform(train['SUBCLASS'])\n",
    "\n",
    "# 변환된 레이블 확인\n",
    "for i, label in enumerate(le_subclass.classes_):\n",
    "    print(f\"원래 레이블: {label}, 변환된 숫자: {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## x 의 경우도 범주형으로 구성되어 있어, 알맞은 인코딩 필요\n",
    "X = train.drop(columns=['SUBCLASS', 'ID'])\n",
    "y_subclass = train['SUBCLASS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 이 코드는 다음과 같이 작동합니다:\n",
    "1. 데이터를 로드합니다.\n",
    "2. 샘플의 변이 데이터를 전처리하여 \"유전자_변이\" 형식의 문자열 리스트로 변환합니다.\n",
    "3. Word2Vec 모델을 사용하여 변이 임베딩을 학습합니다. 여기서는 10차원 벡터를 사용했지만, 이는 조정 가능합니다.\n",
    "4. 각 변이에 대한 임베딩을 가져오는 함수와 각 샘플의 임베딩을 계산하는 함수를 정의합니다. 샘플 임베딩은 해당 샘플의 모든 변이 임베딩의 평균으로 계산됩니다.\n",
    "5. 모든 샘플에 대한 임베딩을 생성합니다.\n",
    "6. SUBCLASS를 숫자로 인코딩합니다.\n",
    "7. 최종 데이터셋을 생성합니다. 이 데이터셋은 샘플 ID, 임베딩 벡터, 인코딩된 SUBCLASS를 포함합니다.\n",
    "8. 이 방법의 장점은 다음과 같습니다:\n",
    "9. 변이 간의 의미적 관계를 포착할 수 있습니다.\n",
    "10. 고차원 데이터를 저차원으로 축소할 수 있습니다.\n",
    "11. 새로운 또는 희귀한 변이에 대해서도 의미 있는 표현을 제공할 수 있습니다.\n",
    "* 단점은 다음과 같습니다:\n",
    "충분한 데이터가 없으면 임베딩의 품질이 떨어질 수 있습니다.\n",
    "하이퍼파라미터 튜닝(예: vector_size, window 등)이 필요할 수 있습니다.\n",
    "이 인코딩 방법을 사용한 후, 결과 데이터셋을 머신러닝 모델의 입력으로 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변이 데이터 전처리\n",
    "def preprocess_mutations(row):\n",
    "    return [f\"{gene}_{mutation}\" for gene, mutation in row.items() if mutation != 'WT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 샘플을 변이 리스트로 변환\n",
    "mutation_sequences = X.apply(preprocess_mutations, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec 모델 학습\n",
    "model = Word2Vec(sentences=mutation_sequences, vector_size=vector_size, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변이 임베딩 함수\n",
    "def get_mutation_embedding(mutation):\n",
    "    if mutation in model.wv:\n",
    "        return model.wv[mutation]\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플 임베딩 함수\n",
    "def get_sample_embedding(mutations):\n",
    "    embeddings = [get_mutation_embedding(mut) for mut in mutations]\n",
    "    return np.mean(embeddings, axis=0) if embeddings else np.zeros(model.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 샘플에 대한 임베딩 생성\n",
    "sample_embeddings = [get_sample_embedding(mutations) for mutations in mutation_sequences]\n",
    "\n",
    "# 임베딩을 DataFrame으로 변환\n",
    "embedding_X = pd.DataFrame(sample_embeddings, columns=[f'embed_{i}' for i in range(model.vector_size)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embed_0</th>\n",
       "      <th>embed_1</th>\n",
       "      <th>embed_2</th>\n",
       "      <th>embed_3</th>\n",
       "      <th>embed_4</th>\n",
       "      <th>embed_5</th>\n",
       "      <th>embed_6</th>\n",
       "      <th>embed_7</th>\n",
       "      <th>embed_8</th>\n",
       "      <th>embed_9</th>\n",
       "      <th>...</th>\n",
       "      <th>embed_90</th>\n",
       "      <th>embed_91</th>\n",
       "      <th>embed_92</th>\n",
       "      <th>embed_93</th>\n",
       "      <th>embed_94</th>\n",
       "      <th>embed_95</th>\n",
       "      <th>embed_96</th>\n",
       "      <th>embed_97</th>\n",
       "      <th>embed_98</th>\n",
       "      <th>embed_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.001129</td>\n",
       "      <td>0.000582</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>-0.000238</td>\n",
       "      <td>-0.000709</td>\n",
       "      <td>-0.000965</td>\n",
       "      <td>-0.001345</td>\n",
       "      <td>0.002244</td>\n",
       "      <td>-0.001245</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001586</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>-0.000369</td>\n",
       "      <td>-0.000753</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>-0.000537</td>\n",
       "      <td>-0.002210</td>\n",
       "      <td>0.000635</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.000986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.004093</td>\n",
       "      <td>-0.000638</td>\n",
       "      <td>-0.002105</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>-0.001026</td>\n",
       "      <td>-0.000330</td>\n",
       "      <td>0.000738</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>-0.001659</td>\n",
       "      <td>-0.000450</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>-0.001717</td>\n",
       "      <td>0.002820</td>\n",
       "      <td>-0.001457</td>\n",
       "      <td>0.001160</td>\n",
       "      <td>-0.001360</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>0.002086</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>0.001064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000853</td>\n",
       "      <td>-0.000413</td>\n",
       "      <td>-0.000039</td>\n",
       "      <td>-0.000454</td>\n",
       "      <td>-0.000490</td>\n",
       "      <td>-0.000972</td>\n",
       "      <td>-0.000729</td>\n",
       "      <td>0.000609</td>\n",
       "      <td>-0.000690</td>\n",
       "      <td>0.000540</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>0.001413</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>-0.000446</td>\n",
       "      <td>-0.000208</td>\n",
       "      <td>-0.000402</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>0.000714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.002286</td>\n",
       "      <td>0.003273</td>\n",
       "      <td>-0.000205</td>\n",
       "      <td>-0.001424</td>\n",
       "      <td>-0.002244</td>\n",
       "      <td>0.002207</td>\n",
       "      <td>-0.001496</td>\n",
       "      <td>-0.003482</td>\n",
       "      <td>0.000563</td>\n",
       "      <td>0.003463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001586</td>\n",
       "      <td>-0.001404</td>\n",
       "      <td>-0.003384</td>\n",
       "      <td>-0.001913</td>\n",
       "      <td>-0.001637</td>\n",
       "      <td>-0.002290</td>\n",
       "      <td>-0.001759</td>\n",
       "      <td>-0.000386</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>0.002159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.000234</td>\n",
       "      <td>-0.001336</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.000899</td>\n",
       "      <td>0.002214</td>\n",
       "      <td>0.001363</td>\n",
       "      <td>0.001679</td>\n",
       "      <td>0.001675</td>\n",
       "      <td>-0.000812</td>\n",
       "      <td>0.002045</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000476</td>\n",
       "      <td>0.000995</td>\n",
       "      <td>0.000920</td>\n",
       "      <td>-0.000197</td>\n",
       "      <td>-0.000370</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.001798</td>\n",
       "      <td>0.002282</td>\n",
       "      <td>-0.000100</td>\n",
       "      <td>0.000584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6196</th>\n",
       "      <td>-0.000454</td>\n",
       "      <td>-0.000521</td>\n",
       "      <td>-0.000143</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.000739</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>0.001881</td>\n",
       "      <td>-0.000353</td>\n",
       "      <td>0.000975</td>\n",
       "      <td>-0.000389</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000364</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.000767</td>\n",
       "      <td>-0.000594</td>\n",
       "      <td>-0.001215</td>\n",
       "      <td>-0.000622</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>-0.000211</td>\n",
       "      <td>0.000256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6197</th>\n",
       "      <td>-0.001165</td>\n",
       "      <td>-0.002464</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.002669</td>\n",
       "      <td>-0.002302</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>-0.000077</td>\n",
       "      <td>0.001693</td>\n",
       "      <td>0.002579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002234</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>0.001624</td>\n",
       "      <td>-0.002102</td>\n",
       "      <td>-0.003690</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>-0.000291</td>\n",
       "      <td>0.000780</td>\n",
       "      <td>-0.001051</td>\n",
       "      <td>-0.000294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6198</th>\n",
       "      <td>0.001183</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>-0.001374</td>\n",
       "      <td>0.002934</td>\n",
       "      <td>0.000702</td>\n",
       "      <td>-0.001328</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>-0.002885</td>\n",
       "      <td>-0.000903</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>-0.000454</td>\n",
       "      <td>0.001892</td>\n",
       "      <td>-0.000737</td>\n",
       "      <td>-0.001684</td>\n",
       "      <td>0.002488</td>\n",
       "      <td>0.000905</td>\n",
       "      <td>0.001542</td>\n",
       "      <td>-0.000469</td>\n",
       "      <td>-0.000451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6199</th>\n",
       "      <td>-0.000064</td>\n",
       "      <td>-0.001094</td>\n",
       "      <td>-0.001524</td>\n",
       "      <td>-0.000040</td>\n",
       "      <td>0.000551</td>\n",
       "      <td>0.001924</td>\n",
       "      <td>-0.000296</td>\n",
       "      <td>0.003042</td>\n",
       "      <td>0.001101</td>\n",
       "      <td>0.002890</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004014</td>\n",
       "      <td>0.001711</td>\n",
       "      <td>-0.002476</td>\n",
       "      <td>-0.001579</td>\n",
       "      <td>0.001287</td>\n",
       "      <td>0.005739</td>\n",
       "      <td>0.001672</td>\n",
       "      <td>0.002546</td>\n",
       "      <td>0.003090</td>\n",
       "      <td>-0.002197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6200</th>\n",
       "      <td>-0.001234</td>\n",
       "      <td>-0.002360</td>\n",
       "      <td>0.000859</td>\n",
       "      <td>-0.000461</td>\n",
       "      <td>0.001384</td>\n",
       "      <td>-0.000032</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>-0.000288</td>\n",
       "      <td>-0.000313</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002436</td>\n",
       "      <td>-0.001399</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>-0.000610</td>\n",
       "      <td>0.000674</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>-0.000545</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>-0.001405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6201 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       embed_0   embed_1   embed_2   embed_3   embed_4   embed_5   embed_6  \\\n",
       "0    -0.001129  0.000582  0.000447 -0.000238 -0.000709 -0.000965 -0.001345   \n",
       "1    -0.004093 -0.000638 -0.002105  0.000170 -0.001026 -0.000330  0.000738   \n",
       "2     0.000853 -0.000413 -0.000039 -0.000454 -0.000490 -0.000972 -0.000729   \n",
       "3    -0.002286  0.003273 -0.000205 -0.001424 -0.002244  0.002207 -0.001496   \n",
       "4    -0.000234 -0.001336  0.000386  0.000899  0.002214  0.001363  0.001679   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "6196 -0.000454 -0.000521 -0.000143  0.000207  0.000739  0.000524  0.001881   \n",
       "6197 -0.001165 -0.002464  0.000024  0.002669 -0.002302 -0.000028  0.000254   \n",
       "6198  0.001183  0.000273  0.000025 -0.001374  0.002934  0.000702 -0.001328   \n",
       "6199 -0.000064 -0.001094 -0.001524 -0.000040  0.000551  0.001924 -0.000296   \n",
       "6200 -0.001234 -0.002360  0.000859 -0.000461  0.001384 -0.000032  0.001667   \n",
       "\n",
       "       embed_7   embed_8   embed_9  ...  embed_90  embed_91  embed_92  \\\n",
       "0     0.002244 -0.001245  0.000941  ... -0.001586  0.000280 -0.000369   \n",
       "1     0.000376 -0.001659 -0.000450  ...  0.000033 -0.001717  0.002820   \n",
       "2     0.000609 -0.000690  0.000540  ...  0.000274  0.001413  0.000347   \n",
       "3    -0.003482  0.000563  0.003463  ...  0.001586 -0.001404 -0.003384   \n",
       "4     0.001675 -0.000812  0.002045  ... -0.000476  0.000995  0.000920   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "6196 -0.000353  0.000975 -0.000389  ... -0.000364  0.000208  0.000767   \n",
       "6197 -0.000077  0.001693  0.002579  ...  0.002234  0.000420  0.001624   \n",
       "6198  0.000574 -0.002885 -0.000903  ...  0.000310 -0.000454  0.001892   \n",
       "6199  0.003042  0.001101  0.002890  ...  0.004014  0.001711 -0.002476   \n",
       "6200 -0.000288 -0.000313  0.000054  ...  0.002436 -0.001399  0.000784   \n",
       "\n",
       "      embed_93  embed_94  embed_95  embed_96  embed_97  embed_98  embed_99  \n",
       "0    -0.000753 -0.000025 -0.000537 -0.002210  0.000635  0.001316  0.000986  \n",
       "1    -0.001457  0.001160 -0.001360  0.000384  0.002086  0.000502  0.001064  \n",
       "2     0.000351  0.000494 -0.000446 -0.000208 -0.000402  0.000369  0.000714  \n",
       "3    -0.001913 -0.001637 -0.002290 -0.001759 -0.000386  0.000941  0.002159  \n",
       "4    -0.000197 -0.000370  0.000238  0.001798  0.002282 -0.000100  0.000584  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "6196 -0.000594 -0.001215 -0.000622  0.000446  0.000194 -0.000211  0.000256  \n",
       "6197 -0.002102 -0.003690  0.000087 -0.000291  0.000780 -0.001051 -0.000294  \n",
       "6198 -0.000737 -0.001684  0.002488  0.000905  0.001542 -0.000469 -0.000451  \n",
       "6199 -0.001579  0.001287  0.005739  0.001672  0.002546  0.003090 -0.002197  \n",
       "6200  0.000149 -0.000610  0.000674  0.000309 -0.000545  0.000046 -0.001405  \n",
       "\n",
       "[6201 rows x 100 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f\"label_encoding_mutation_model_vector_{vector_size}.w2v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = Word2Vec.load(f\"label_encoding_mutation_model_vector_{vector_size}.w2v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.drop([\"ID\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_test_sample(sample, model):\n",
    "    mutations = preprocess_mutations(sample)\n",
    "    return get_sample_embedding(mutations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터 인코딩\n",
    "test_embeddings = [encode_test_sample(sample, loaded_model) for _, sample in X_test.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_X_test = pd.DataFrame(test_embeddings, columns=[f'embed_{i}' for i in range(loaded_model.vector_size)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_X.to_csv(f'../data/vector_{vector_size}_embeding_X.csv', encoding='UTF-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_X_test.to_csv(f'../data/vector_{vector_size}_embeding_X_test.csv', encoding='UTF-8-sig', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lsrr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
